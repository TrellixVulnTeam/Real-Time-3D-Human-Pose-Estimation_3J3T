{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 视频3d姿势估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import detectron2\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"../../\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取视频和显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/home/li/python/pose-estimation/3d/VideoPose3D/data/pose2d-detectron2/')\n",
    "video_path = '../videos/lizijun.mp4'\n",
    "\n",
    "def read_video(filepath):\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    # 帧率\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    pause = int(1000 * (1/fps))\n",
    "    # 宽高\n",
    "    cv2.namedWindow('Video', 0)\n",
    "    cv2.resizeWindow('Video',  1280, 720)\n",
    "    while True:\n",
    "        #  获取帧\n",
    "        ret_val, frame = cap.read()\n",
    "        if ret_val != 1:\n",
    "            break\n",
    "        # 显示帧\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(pause) & 0xff == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# read_video(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 2d关键点检测器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换工作目录\n",
    "# os.chdir('/home/li/python/pose-estimation/3d/VideoPose3D/data/pose2d-detectron2/')\n",
    "\n",
    "def init_kps_predictor(config_path, weights_path, cuda=True):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_path)\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "    cfg.MODEL.WEIGHTS = weights_path\n",
    "    if cuda == False:\n",
    "        cfg.MODEL.DEVICE='cpu'\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    \n",
    "    return predictor\n",
    "\n",
    "model_config_path = './keypoint_rcnn_R_50_FPN_3x.yaml'\n",
    "model_weights_path = './model_R50.pkl'\n",
    "kps_predictor = init_kps_predictor(model_config_path, model_weights_path, cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 2d关键点检测和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_screen_coordinates(X, w, h): \n",
    "    assert X.shape[-1] == 2\n",
    "    \n",
    "    # Normalize so that [0, w] is mapped to [-1, 1], while preserving the aspect ratio\n",
    "    return X/w*2 - [1, h/w]\n",
    "\n",
    "def predict_kps(kps_predictor, img):\n",
    "    '''\n",
    "        kps_predictor: The detectron's 2d keypoints predictor\n",
    "        img_generator:  Images source\n",
    "    '''\n",
    "    # Predict kps:\n",
    "    pose_output = kps_predictor(img)\n",
    "\n",
    "    if len(pose_output[\"instances\"].pred_boxes.tensor) > 0:\n",
    "        kps = pose_output[\"instances\"].pred_keypoints[0].cpu().numpy()\n",
    "    else:\n",
    "        kps = np.full((17,3), np.nan, dtype=np.float32)   # nan for images that do not contain human\n",
    "    # 标准化，去掉概率列，只保留坐标值\n",
    "    kps = normalize_screen_coordinates(kps[..., :2], w=img.shape[1], h=img.shape[0])\n",
    "    return kps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 3d姿势估计器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_dir = os.getcwd()\n",
    "# os.chdir('/home/li/python/pose-estimation/3d/VideoPose3D')\n",
    "# print(\"Change work dir from {} to {}\".format(prev_dir, os.getcwd()))\n",
    "from common.model import *\n",
    "\n",
    "\n",
    "def get_pose3d_predictor(ckpt_dir, ckpt_name, filter_widths, causal=False):\n",
    "    ckpt_path = os.path.join(ckpt_dir, ckpt_name)\n",
    "    print('Loading checkpoint', ckpt_path)\n",
    "    checkpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "    print('This model was trained for {} epochs'.format(checkpoint['epoch']))\n",
    "    \n",
    "    pose3d_predictor = TemporalModel(17, 2 ,17, filter_widths=filter_widths, causal=causal)\n",
    "    receptive_field = pose3d_predictor.receptive_field()\n",
    "    print('INFO: Receptive field: {} frames'.format(receptive_field))\n",
    "    pose3d_predictor.load_state_dict(checkpoint['model_pos'])\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        pose3d_predictor = pose3d_predictor.cuda()\n",
    "    \n",
    "    return pose3d_predictor.eval()\n",
    "\n",
    "\n",
    "ckpt_dir = '../../checkpoint/detectron_pt_coco'\n",
    "ckpt_name = 'arc_1_epoch_40.bin'\n",
    "filter_widths = [1,1,1]\n",
    "pose3d_predictor = get_pose3d_predictor(ckpt_dir, ckpt_name, filter_widths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 2d关键点生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.camera import *\n",
    "from common.generators import UnchunkedGenerator\n",
    "\n",
    "kps_left=[1, 3, 5, 7, 9, 11, 13, 15]\n",
    "kps_right=[2, 4, 6, 8, 10, 12, 14, 16]\n",
    "def kps_generator(pose3d_predictor, kps):\n",
    "#     receptive_field = pose3d_predictor.receptive_field()\n",
    "#     pad = (receptive_field - 1) // 2  # Padding on each side\n",
    "    pad = 0\n",
    "    causal_shift = 0\n",
    "    \n",
    "#     print('kps.shape:' , kps.shape)\n",
    "    # 创建生成器作为3d预测器的输入\n",
    "    generator = UnchunkedGenerator(None, None, [kps], pad=pad, causal_shift=causal_shift, augment=True, kps_left=kps_left, kps_right=kps_right)\n",
    "    return generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 图像渲染函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation, writers\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 画图\n",
    "def render_image(keypoints, pos_3d, skeleton, azim, input_video_frame=None):\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=120)\n",
    "    canvas = FigureCanvas(fig)\n",
    "    # plot input frame\n",
    "    ax_in = fig.add_subplot(1, 2, 1)\n",
    "    ax_in.get_xaxis().set_visible(False)\n",
    "    ax_in.get_yaxis().set_visible(False)\n",
    "    ax_in.set_axis_off()\n",
    "    ax_in.set_title('Input')\n",
    "    ax_in.imshow(input_video_frame, aspect='equal')\n",
    "    \n",
    "    # 3D\n",
    "    ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax.view_init(elev=15., azim=azim)\n",
    "    # set 长度范围\n",
    "    radius = 2.0\n",
    "    ax.set_xlim3d([-radius / 2, radius / 2])\n",
    "    ax.set_zlim3d([0, radius])\n",
    "    ax.set_ylim3d([-radius / 2, radius / 2])\n",
    "    ax.set_aspect('equal')\n",
    "    # 坐标轴刻度\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "    ax.dist = 7.5\n",
    "    ax.set_title('3D Pose Reconstruction')\n",
    "\n",
    "    # lxy add\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "\n",
    "    # array([-1,  0,  1,  2,  0,  4,  5,  0,  7,  8,  9,  8, 11, 12,  8, 14, 15])\n",
    "    parents = skeleton.parents()\n",
    "\n",
    "    pos = pos_3d\n",
    "    for j, j_parent in enumerate(parents):\n",
    "        if j_parent == -1:\n",
    "            continue\n",
    "\n",
    "        if len(parents) == keypoints.shape[1]:\n",
    "            color_pink = 'pink'\n",
    "            if j == 1 or j == 2:\n",
    "                color_pink = 'black'\n",
    "\n",
    "        col = 'red' if j in skeleton.joints_right() else 'black'\n",
    "        # 画图3D\n",
    "        ax.plot([pos[j, 0], pos[j_parent, 0]],\n",
    "                [pos[j, 1], pos[j_parent, 1]],\n",
    "                [pos[j, 2], pos[j_parent, 2]], zdir='z', c=col)\n",
    "\n",
    "    width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "    canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8').reshape(int(height), int(width), 3)\n",
    "    plt.close()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 3d关键点预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_left = [4, 5, 6, 11, 12, 13] \n",
    "joints_right = [1, 2, 3, 14, 15, 16]\n",
    "\n",
    "class Skeleton:\n",
    "    def parents(self):\n",
    "        return np.array([-1, 0, 1, 2, 0, 4, 5, 0, 7, 8, 9, 8, 11, 12, 8, 14, 15])\n",
    "\n",
    "    def joints_right(self):\n",
    "        return [1, 2, 3, 9, 10]\n",
    "\n",
    "# 预测3d坐标\n",
    "def predict_3d_pos(test_generator, predictor):\n",
    "    with torch.no_grad():\n",
    "        predictor.eval()\n",
    "        for _, batch, batch_2d in test_generator.next_epoch():\n",
    "            inputs_2d = torch.from_numpy(batch_2d.astype('float32'))\n",
    "            if torch.cuda.is_available():\n",
    "                inputs_2d = inputs_2d.cuda()\n",
    "            # Positional model\n",
    "            predicted_3d_pos = predictor(inputs_2d)\n",
    "            \n",
    "            # Test-time augmentation (if enabled)\n",
    "            if test_generator.augment_enabled():\n",
    "                # Undo flipping and take average with non-flipped version\n",
    "                predicted_3d_pos[1, :, :, 0] *= -1\n",
    "                predicted_3d_pos[1, :, joints_left + joints_right] = predicted_3d_pos[1, :, joints_right + joints_left]\n",
    "                predicted_3d_pos = torch.mean(predicted_3d_pos, dim=0, keepdim=True)\n",
    "            \n",
    "            return predicted_3d_pos.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 视频3d姿势估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_pose(filepath, \n",
    "               ckpt_dir = '../../checkpoint/detectron_pt_coco', \n",
    "               ckpt_name = 'arc_1_epoch_40.bin',\n",
    "               filter_widths = [1,1,1],\n",
    "               show=False):\n",
    "    \n",
    "    # 加载3d姿势估计器\n",
    "    pose3d_predictor = get_pose3d_predictor(ckpt_dir, ckpt_name, filter_widths)\n",
    "    \n",
    "    # 初始化2d检测器\n",
    "    model_config_path = './keypoint_rcnn_R_50_FPN_3x.yaml'\n",
    "    model_weights_path = './model_R50.pkl'\n",
    "    kps_predictor = init_kps_predictor(model_config_path, model_weights_path, cuda=False)\n",
    "    \n",
    "    receive_field = 1\n",
    "    for i in filter_widths:\n",
    "        receive_field *= i\n",
    "#     print(receive_field)\n",
    "    half = receive_field // 2\n",
    "    # 读取视频\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    cap.set(3,1080) #设置分辨率\n",
    "    cap.set(4,720)\n",
    "    # 帧率\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    pause = int(1000 * (1/fps))\n",
    "    \n",
    "    if show:\n",
    "        # 宽高\n",
    "        cv2.namedWindow('Video', 0)\n",
    "        cv2.resizeWindow('Video',  960, 480)\n",
    "    \n",
    "    # 帧率\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # 保存视频文件\n",
    "    wh = (1080, 720)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    output_avi = cv2.VideoWriter('output.mp4', fourcc, fps, wh)\n",
    "\n",
    "    kps_list = []\n",
    "    frame_list = []\n",
    "    i = 0\n",
    "    # 因为设置了数据生成器的pad=0，因此需要获取前receive_field//2帧做准备\n",
    "    print(\"Preparing...\")\n",
    "    while i < half:\n",
    "        ret_val, frame = cap.read()\n",
    "        if ret_val != 1:\n",
    "                print(\"Video is too short!\")\n",
    "                output_avi.release()\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "        try:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_list.append(frame)\n",
    "        except:\n",
    "            continue\n",
    "        # 生成2d关键点\n",
    "        kps = predict_kps(kps_predictor, frame)\n",
    "        kps_list.append(kps)\n",
    "        i += 1\n",
    "    \n",
    "    print(\"Starting to predict 3d pose...\")\n",
    "    fps_time = time.time()\n",
    "    while True:\n",
    "        #  获取帧\n",
    "        i += 1\n",
    "        if len(frame_list) < 1:\n",
    "            break\n",
    "        ret_val, frame = cap.read()\n",
    "        if ret_val == 1:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_list.append(frame)\n",
    "            # 生成2d关键点\n",
    "            kps = predict_kps(kps_predictor, frame)\n",
    "            kps_list.append(kps)\n",
    "        \n",
    "        frame = frame_list[0]\n",
    "        if i > half + 1:\n",
    "            # 去除最左端的无用帧\n",
    "            kps_list = kps_list[1:]\n",
    "            frame_list = frame_list[1:]\n",
    "        \n",
    "        if len(kps_list) < receive_field:\n",
    "            if i < receive_field:\n",
    "                # 视频开头小于receive_field帧时，在左边进行pad操作\n",
    "#                 print(\"kps_list length is {}, padding {} frames to left end.\".format(len(kps_list), half))\n",
    "                while len(kps_list) < receive_field:\n",
    "                    kps_list.insert(0, kps_list[0])\n",
    "            else:\n",
    "                # 视频末尾不足receive_field帧时，在右边进行pad操作\n",
    "#                 print(\"kps_list length is {}, padding 1 frames to right end.\".format(len(kps_list)))\n",
    "                kps_list.append(kps_list[-1])\n",
    "        \n",
    "        # 构造2d关键点生成器\n",
    "        kps_2d = np.stack(kps_list)\n",
    "        generator = kps_generator(pose3d_predictor, kps_2d)\n",
    "#         print(generator.num_frames())\n",
    "        \n",
    "        # 3d关键点预测\n",
    "        predictions = predict_3d_pos(generator, pose3d_predictor)\n",
    "#         print('predictions.shape: ', predictions.shape)\n",
    "\n",
    "        rot = np.array([0.14070565, -0.15007018, -0.7552408, 0.62232804], dtype=np.float32)\n",
    "        predictions = camera_to_world(predictions, R=rot, t=0)\n",
    "        # We don't have the trajectory, but at least we can rebase the height\n",
    "        predictions[:, :, 2] -= np.min(predictions[:, :, 2])\n",
    "        \n",
    "        pos_3d = predictions[0]\n",
    "        kps_2d = image_coordinates(kps_2d[..., :2], w=1080, h=720)\n",
    "        pos_2d = kps_2d[0]\n",
    "        \n",
    "#         print('predicted {} frame, elapsed time: {:.3f} seconds.'.format(predictions.shape[0], time.time() - fps_time))\n",
    "        fps = 1.0 / (time.time() - fps_time)\n",
    "        \n",
    "        # 渲染图像\n",
    "        result_image = render_image(pos_2d, pos_3d=pos_3d, skeleton=Skeleton(), azim=np.array(70., dtype=np.float32),  input_video_frame=frame)\n",
    "        cv2.putText(result_image, \"FPS: %f\" % (fps), (10, 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        result_image = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # resize and write\n",
    "        to_write = cv2.resize(result_image, wh)\n",
    "        output_avi.write(to_write)\n",
    "\n",
    "        if show:\n",
    "            # 显示帧\n",
    "            cv2.imshow('Video', result_image)\n",
    "            if cv2.waitKey(pause) & 0xff == ord('q'):\n",
    "                break\n",
    "        fps_time = time.time()\n",
    "    output_avi.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "# os.chdir('/home/li/python/pose-estimation/3d/VideoPose3D/data/pose2d-detectron2/')\n",
    "video_path = '../videos/huaban_01-08.mp4'\n",
    "video_pose(video_path, ckpt_name = 'arc_27_epoch_40.bin', filter_widths=[3, 3 ,3])\n",
    "print(\"Finish prediction...\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 读取27帧图像并检测出2d关键点坐标\n",
    "2. 构造2d关键点生成器\n",
    "3. 预测3d关键点坐标\n",
    "4. 显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}